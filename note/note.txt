

nobn loss居高不下 保持在110到130左右
bn在relu前 20save，loss在33到43，均值37左右，四角白9%，四角黑84%，三黑66%，三黑一白41%(???)，四白悬空65%
bn在relu后 50save，                         四角白14%，四角黑71%，三黑44%(???)，三黑一白33%(???)
对结算的规则（数子多少）有比较好的了解，但还是不够深刻
比如
[x, x, x, x, x, x, x, x],
[x, o, o, o, o, o, o, x],
[x, o, o, o, o, o, o, x],
[o, o, o, o, o, o, o, o],
[o, o, o, o, o, o, o, o],
[x, o, o, o, o, o, o, x],
[x, o, o, o, o, o, o, x],
[x, x, x, x, x, x, x, x]]
判断的黑棋胜率达到了84%


调个模型
现在收敛太快了，loss维持在1000
lr减小，sigmoid换tanh（zero的论文里是tanh），加深CNN
然后考虑上resnet

lr: 0.003 min_cost: 1020
lr: 0.001 min_cost: 1060
lr: 0.009 min_cost: 1030
lr的更改无太大意义
tanh没用

1.23
jb，基础不扎实，没意识到loss取mean和sum是完全不一样的，sum的学习率相当于mean的batchsize倍，我的batchsize一直是256，也就是说lr约为0.75，大到爆了。
改了以后发现resnet效果确实好，不过之前的实验结果白费了
momentum=0.9收敛不知道快了多少倍,第4代超过了没momentum的第23代
tanh确实比sigmoid收敛快那么一点点
tanh:						sigmoid * 4:
0: [1.8026668]				0: [1.510188]
1: [0.7825338]				1: [0.7934871]
2: [0.75040126]				2: [0.7542679]
3: [0.73562586]				3: [0.73684645]
4: [0.7249321]				4: [0.72723097]
5: [0.7194749]				5: [0.72312516]
6: [0.7136518]				6: [0.71688646]
7: [0.71161443]				7: [0.7154234]
8: [0.7049715]				8: [0.7131796]
9: [0.7061127]
10: [0.70104873]
11: [0.6994134]
可以看到tanh的loss仍然没有完全收敛，5res
1res 收敛的居然也不错 可能是vnet任务比较简单
momentum = 0.999原地爆炸

network_input[x, y, 0] = self.board[x, y] == -1 ...
也就是说不需要输入o棋子效果居然也还可以。。
神经网络真nm神奇

1.24 凌晨
得到了目前效果最好的一次测试，比预计的好太多
诸多优化方法表现出了他们的巨大作用，l2，bn，res缺一不可，收敛曲线非常优美。180代仍没有过拟合现象，model应该可以说确实理解了reversi。

截一下
3: 9.886002	0.75489354	3.9451668 # 分布基本随机
13: 9.002726	0.7167425	3.1613307
28: 8.575691	0.70082784	2.840983
36: 8.398759	0.69117665	2.7213159
44: 8.250599	0.69096583	2.620745 # 有点意思
54: 8.079334	0.6938613	2.5049047
... # vloss小幅震荡，总体上有极小幅下降，ploss基本呈线性下降，这是一个问题
160: 6.6610856	0.66839665	1.6884536 # 完全理解
176: 6.5381756	0.6656988	1.649105
179: 6.5073776	0.6648126	1.634224
184: 6.481653	0.660802	1.6372353
190: 6.445794	0.67378765	1.6181046
191: 6.4422464	0.6760389	1.6172347
192: 6.4345613	0.66460395	1.625716
193: 6.4181757	0.6675206	1.6113294

没法训练完了，噪声太大，还要睡觉，可以看到loss整体还在不断降低，现在降得很多是l2loss

通过结算规则实验感觉vnet还可以提高，pass大概在15%-30%，胜率依然在黑，（不过还是那句话，可能是样本的问题。。。，或者说这种根本达不到的局面，预测不准也正常）

现在的问题有l2loss占比太高，应该尝试调一下；lr可能太低，ploss线性下降太慢；res表现出了价值，层数应该如何提高一下；fc层有没有必要增加unit，phead多连一层；收敛太慢太慢，这样用MCT迭代的话不知道要搞多久，需要权衡一下时间与性能
这些搞完就只差个MCTS了，搞个模板应该不难，但还要考虑有没有必要cython一下

突然感觉一个问题，样本的policy是通过一个固定的概率分布（滤镜）生成的，也就是说p的复杂度很低，低层网络就完全能学到，那么用高res和低res训练出来的差别应该不大，因为太简单了。还是要试验一下

结果出来了，5res，lr=0.1 -> 0.01
125:	2.00319	0.67784	1.15704
126:	1.99237	0.66996	1.15529
127:	1.98386	0.66549	1.15240
15:	1.96789	0.68569	1.10804
16:	1.96137	0.67915	1.10865
17:	1.96995	0.69119	1.10575

3res, lr=0.03 -> 0.003
185:	2.39203	0.68004	1.25695
186:	2.41022	0.69726	1.26164
187:	2.38508	0.68760	1.24984
10:	2.35157	0.70279	1.20612
11:	2.35862	0.70794	1.20852
12:	2.35507	0.70485	1.20855
可以看到还是有区别的，ploss差了个0.1
3res从22:06 -> 25:00，耗时还是个大问题
明天正式开始搞MCTS